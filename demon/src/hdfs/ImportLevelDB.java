package hdfs;import java.io.IOException;import java.net.URI;import java.util.concurrent.atomic.AtomicLong;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FileStatus;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;public class ImportLevelDB {	public static AtomicLong increace_thread_complate_flag = new AtomicLong(0);	public static void main(String[] args) {		System.out.println("程序开始运行.........");		String zookeeperhost_ip = null;		// 从zookeeper中读取数据		// 写入levelDB 数据文件路径		//String leveldb_data_path = args[0];		// 数据源文件目录		String org_data_path = "/";		Configuration conf = new Configuration();		// conf.addResource("/usr/local/hadoop-2.0.0-cdh4.0.0/etc/hadoop/core-site.xml");		// conf.addResource("/usr/local/hadoop-2.0.0-cdh4.0.0/etc/hadoop/hdfs-site.xml");		FileStatus[] stats = null;		int file_size = 1;		try {			//FileSystem hdfs = DistributedFileSystem.get(conf);			//Path listf = new Path("hdfs://172.16.0.90:9000" + org_data_path);			String dst = "hdfs://hadoop-1:9000/";			FileSystem fs = FileSystem.get(URI.create(dst), conf);			Path listf = new Path("/");			stats = fs.listStatus(listf);			file_size = stats.length;			System.out.println("hadoop 问价系统加载成功:"+file_size);		} catch (IOException e2) {			System.out.println("hadoop 文件系统加载失败");			e2.printStackTrace();			return;		}	}}