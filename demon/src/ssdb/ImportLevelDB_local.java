package ssdb;import java.io.BufferedReader;import java.io.ByteArrayOutputStream;import java.io.DataOutputStream;import java.io.File;import java.io.FileInputStream;import java.io.IOException;import java.io.InputStreamReader;import java.net.URI;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.atomic.AtomicLong;import net.sf.json.JSONObject;import org.apache.commons.lang.StringUtils;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FSDataInputStream;import org.apache.hadoop.fs.FileStatus;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;import org.apache.zookeeper.WatchedEvent;import org.apache.zookeeper.Watcher;import org.apache.zookeeper.ZooKeeper;import org.apache.zookeeper.data.Stat;import org.fusesource.leveldbjni.JniDBFactory;import org.iq80.leveldb.DB;import org.iq80.leveldb.DBFactory;import org.iq80.leveldb.Options;public class ImportLevelDB_local {	public static AtomicLong increace_thread_complate_flag = new AtomicLong(0);	public static long start = 0l;	static DB db = null;	static double avg_status_num_max = 500;	public static void main(String[] args) {		System.out.println("程序开始运行.........");		ExecutorService executorService = Executors.newFixedThreadPool(5);		DBFactory factory = JniDBFactory.factory;		Options options = new Options().createIfMissing(true);		String leveldb_data_path = "/home/pubsrv/ssdb-master/var/define/data";		try {			db = factory.open(new File(leveldb_data_path), options);		} catch (IOException e1) {			System.out.println(leveldb_data_path + "数据文件打开失败:" + e1);			e1.printStackTrace();		}		start = System.currentTimeMillis();		String path = args[0];		System.out.println(path + " 数据开始写入 start time:" + start);		wirte(path);		System.out.println("数据导入完毕===============共运行"				+ (System.currentTimeMillis() - start) / 1000 + "秒");		try {			if (db != null) {				db.close();			}			executorService.shutdown();		} catch (IOException e) {			System.out.println(leveldb_data_path + "数据库关闭失败");			e.printStackTrace();		}	}	static String parseDataAttr = "navy_base_data,agent,every_hour_status_count,avg_forward_status,avg_commemts_status,interact_user,avg_status_num";	private static BufferedReader reader;	public static void wirte(String path) {		try {			reader = new BufferedReader(new InputStreamReader(					new FileInputStream(path)));			String line = null;			String[] attrs = StringUtils.splitByWholeSeparator(parseDataAttr,					",");			while ((line = reader.readLine()) != null) {				JsonToLevelDB(attrs, line);			}		} catch (Exception e) {			System.out.println("运行" + "失败" + e);			e.printStackTrace();		} finally {			ImportLevelDB_local.increace_thread_complate_flag.incrementAndGet();		}	}	public static void JsonToLevelDB(String[] attrs, String json) {		JSONObject jsonObject = JSONObject.fromObject(json);		String uid = jsonObject.getString(attrs[0]);		// 解析出字段写入 leveldb		for (int i = 1; i < attrs.length; i++) {			// 水度			if ("navy_base_data".equals(attrs[i])) {				String shuidubase = jsonObject.getString("navy_base_data");				/*				 * String[] navys =				 * StringUtils.splitByWholeSeparator(shuidubase, "-"); double				 * zhunafalav = Double.valueOf(navys[3]); double zhuanfa =				 * Double.valueOf(navys[1]); double dnavy = 0; if(zhunafalav > 0				 * && zhuanfa > 0){ dnavy =				 * Double.valueOf(navys[3])/Double.valueOf(navys[1]); dnavy =				 * Math.round(dnavy * 100000)/ 100000d; }				 */				String levelkey = encodeHashCode(uid, "shuidu");				db.put(org.fusesource.leveldbjni.JniDBFactory.bytes(levelkey),						org.fusesource.leveldbjni.JniDBFactory								.bytes(shuidubase));				// 活跃度			} else if ("avg_status_num".equals(attrs[i])) {				double avg_status_num = jsonObject.getDouble("avg_status_num");				double rate = avg_status_num / avg_status_num_max;				double liveness = Math.log((double) (rate + 1)) / Math.log(2);				liveness = Math.round(liveness * 100000) / 100000d;				if (liveness > 1) {					liveness = Double.valueOf(String.valueOf(liveness)							.replaceAll("\\d+\\.[0-9]{1}", "0.9"));				}				String levelkey = encodeHashCode(uid, "liveness");				db.put(org.fusesource.leveldbjni.JniDBFactory.bytes(levelkey),						org.fusesource.leveldbjni.JniDBFactory.bytes(String								.valueOf(liveness)));			} else {				String value = jsonObject.getString(attrs[i]);				String levelkey = encodeHashCode(uid, attrs[i]);				db.put(org.fusesource.leveldbjni.JniDBFactory.bytes(levelkey),						org.fusesource.leveldbjni.JniDBFactory.bytes(value));			}		}	}	public static String encodeHashCode(String hashname, String key) {		ByteArrayOutputStream bos = new ByteArrayOutputStream(512);		DataOutputStream dos = new DataOutputStream(bos);		String result = "";		try {			dos.writeBytes("h");			dos.write(hashname.getBytes().length);			dos.writeBytes(hashname);			dos.writeBytes("=");			dos.writeBytes(key);			result = bos.toString();			bos.reset();		} catch (IOException e) {			System.out.println("hash key 编译失败......hashname:" + hashname					+ "key:" + key);			e.printStackTrace();		}		return result;	}}